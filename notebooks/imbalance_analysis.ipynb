{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imbalance Handling Techniques Analysis for Readmission Prediction\n",
    "\n",
    "This notebook analyzes and compares different techniques for handling class imbalance in the readmission prediction model:\n",
    "\n",
    "1. Baseline (no imbalance handling)\n",
    "2. Class weights (class_weight='balanced')\n",
    "3. Random oversampling\n",
    "4. SMOTE (Synthetic Minority Over-sampling Technique)\n",
    "5. Random undersampling\n",
    "\n",
    "For each technique, we generate:\n",
    "- PR curves\n",
    "- F1 scores\n",
    "- Precision\n",
    "- Recall\n",
    "- PR AUC\n",
    "\n",
    "All metrics are computed using cross-validation to ensure robust evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from typing import Dict, List, Optional, Tuple, Any\n",
    "\n",
    "# Add project root to path\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "\n",
    "# Import project modules\n",
    "from src.utils import get_logger, load_config, get_data_path, get_project_root\n",
    "from src.models.model import ReadmissionModel\n",
    "from src.models.imbalance_analysis import (\n",
    "    load_data, preprocess_data, create_imbalance_pipelines,\n",
    "    evaluate_pipelines, plot_pr_curves, plot_metrics_comparison,\n",
    "    save_results_to_csv, analyze_imbalance_techniques\n",
    ")\n",
    "\n",
    "# Set up logging\n",
    "logger = get_logger(__name__)\n",
    "\n",
    "# Set plot style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load and Explore Data\n",
    "\n",
    "First, let's load the data and explore the class distribution to understand the imbalance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data = load_data()\n",
    "print(f\"Loaded data with {data.shape[0]} rows and {data.shape[1]} columns\")\n",
    "\n",
    "# Display first few rows\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess data\n",
    "X, y = preprocess_data(data)\n",
    "print(f\"Preprocessed features shape: {X.shape}\")\n",
    "\n",
    "# Visualize class distribution\n",
    "class_counts = y.value_counts()\n",
    "plt.figure(figsize=(10, 6))\n",
    "ax = sns.barplot(x=class_counts.index, y=class_counts.values)\n",
    "plt.title('Class Distribution for 30-day Readmission')\n",
    "plt.xlabel('Readmission')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "# Add percentage labels\n",
    "total = len(y)\n",
    "for i, count in enumerate(class_counts.values):\n",
    "    percentage = count / total * 100\n",
    "    ax.text(i, count + 5, f\"{count} ({percentage:.1f}%)\", ha='center')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Print imbalance ratio\n",
    "imbalance_ratio = class_counts.iloc[0] / class_counts.iloc[1] if class_counts.iloc[0] > class_counts.iloc[1] else class_counts.iloc[1] / class_counts.iloc[0]\n",
    "print(f\"Imbalance ratio: {imbalance_ratio:.2f}:1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Implement and Evaluate Imbalance Handling Techniques\n",
    "\n",
    "Now, let's implement and evaluate different techniques for handling the class imbalance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pipelines for different techniques\n",
    "pipelines = create_imbalance_pipelines(random_state=42)\n",
    "print(f\"Created {len(pipelines)} pipelines for evaluation:\")\n",
    "for name in pipelines.keys():\n",
    "    print(f\"- {name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate pipelines using cross-validation\n",
    "results = evaluate_pipelines(X, y, pipelines, cv_folds=5, random_state=42)\n",
    "\n",
    "# Create a summary dataframe\n",
    "summary = []\n",
    "for name, result in results.items():\n",
    "    summary.append({\n",
    "        \"Technique\": name,\n",
    "        \"Precision\": result[\"precision\"],\n",
    "        \"Recall\": result[\"recall\"],\n",
    "        \"F1 Score\": result[\"f1\"],\n",
    "        \"PR AUC\": result[\"pr_auc\"]\n",
    "    })\n",
    "\n",
    "summary_df = pd.DataFrame(summary)\n",
    "summary_df.set_index(\"Technique\", inplace=True)\n",
    "summary_df.style.highlight_max(axis=0, color='lightgreen').format(\"{:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Visualize Results\n",
    "\n",
    "### 3.1 Precision-Recall Curves\n",
    "\n",
    "PR curves are particularly useful for imbalanced classification problems as they focus on the minority class performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot PR curves\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "for name, result in results.items():\n",
    "    if result[\"precision_curve\"] is not None and result[\"recall_curve\"] is not None:\n",
    "        plt.plot(\n",
    "            result[\"recall_curve\"], \n",
    "            result[\"precision_curve\"],\n",
    "            label=f\"{name} (PR AUC = {result['pr_auc']:.3f})\"\n",
    "        )\n",
    "\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.title(\"Precision-Recall Curves for Different Imbalance Handling Techniques\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Metrics Comparison\n",
    "\n",
    "Let's compare the key metrics (Precision, Recall, F1, PR AUC) across all techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot metrics comparison\n",
    "metrics = [\"precision\", \"recall\", \"f1\", \"pr_auc\"]\n",
    "pipeline_names = list(results.keys())\n",
    "\n",
    "# Extract metrics for each pipeline\n",
    "metric_values = {metric: [results[name][metric] for name in pipeline_names] for metric in metrics}\n",
    "\n",
    "# Create the plot\n",
    "fig, ax = plt.subplots(figsize=(14, 8))\n",
    "\n",
    "x = np.arange(len(pipeline_names))\n",
    "width = 0.2\n",
    "multiplier = 0\n",
    "\n",
    "for metric, values in metric_values.items():\n",
    "    offset = width * multiplier\n",
    "    rects = ax.bar(x + offset, values, width, label=metric.upper())\n",
    "    ax.bar_label(rects, fmt=\"{:.2f}\", padding=3)\n",
    "    multiplier += 1\n",
    "\n",
    "ax.set_ylabel(\"Score\")\n",
    "ax.set_title(\"Comparison of Metrics Across Imbalance Handling Techniques\")\n",
    "ax.set_xticks(x + width, pipeline_names)\n",
    "ax.legend(loc=\"upper left\", bbox_to_anchor=(1, 1))\n",
    "ax.set_ylim(0, 1)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Heatmap of Metrics\n",
    "\n",
    "A heatmap can provide a clear visual comparison of all metrics across techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create heatmap\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(summary_df, annot=True, cmap=\"YlGnBu\", fmt=\".3f\", linewidths=.5)\n",
    "plt.title(\"Heatmap of Evaluation Metrics Across Imbalance Handling Techniques\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Discussion of Trade-offs\n",
    "\n",
    "Let's analyze the trade-offs between different imbalance handling techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Baseline vs. Class Weights\n",
    "\n",
    "Class weights adjust the importance of each class during training, which can help the model pay more attention to the minority class without changing the data. This typically improves recall at the expense of precision.\n",
    "\n",
    "Let's compare the metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare Baseline vs. Class Weights\n",
    "comparison_df = summary_df.loc[[\"Baseline\", \"Class Weights\"]]\n",
    "comparison_df.style.highlight_max(axis=0, color='lightgreen').format(\"{:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Random Oversampling vs. SMOTE\n",
    "\n",
    "Random oversampling duplicates existing minority samples, which can lead to overfitting as the model sees the exact same minority samples multiple times.\n",
    "\n",
    "SMOTE creates synthetic examples by interpolating between existing minority samples, which can help the model generalize better by learning from a more diverse set of minority class examples.\n",
    "\n",
    "SMOTE may perform differently than random oversampling because it creates new, synthetic samples rather than just duplicating existing ones, potentially leading to better generalization but possibly introducing noise if the synthetic samples are not representative of the true data distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare Random Oversampling vs. SMOTE\n",
    "comparison_df = summary_df.loc[[\"Random Oversampling\", \"SMOTE\"]]\n",
    "comparison_df.style.highlight_max(axis=0, color='lightgreen').format(\"{:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Oversampling vs. Undersampling\n",
    "\n",
    "Oversampling techniques (Random Oversampling, SMOTE) increase the number of minority class samples to balance the classes, preserving all available information but potentially leading to longer training times and overfitting.\n",
    "\n",
    "Undersampling reduces the number of majority class samples, which can lead to information loss but may help prevent the model from being biased towards the majority class and can reduce training time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare Oversampling vs. Undersampling\n",
    "comparison_df = summary_df.loc[[\"Random Oversampling\", \"SMOTE\", \"Random Undersampling\"]]\n",
    "comparison_df.style.highlight_max(axis=0, color='lightgreen').format(\"{:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Conclusion\n",
    "\n",
    "### Key Findings\n",
    "\n",
    "Based on the analysis above, we can draw the following conclusions:\n",
    "\n",
    "1. **Best Overall Technique**: [To be filled based on actual results]\n",
    "2. **Precision-Recall Trade-off**: [To be filled based on actual results]\n",
    "3. **SMOTE vs. Random Oversampling**: [To be filled based on actual results]\n",
    "\n",
    "### Limitations\n",
    "\n",
    "It's important to note the limitations of this analysis:\n",
    "\n",
    "1. **Small Dataset Size**: With only ~200 demo patients, the absolute performance metrics may be unstable and not generalizable. The relative differences between techniques are more informative than the absolute values.\n",
    "\n",
    "2. **Cross-validation Stability**: Even with cross-validation, the small dataset size means that the results may vary significantly depending on the random splits.\n",
    "\n",
    "3. **Model Simplicity**: We used logistic regression for all techniques to focus on the imbalance handling methods, but more complex models might interact differently with these techniques.\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "For a more comprehensive analysis, consider:\n",
    "\n",
    "1. Testing these techniques on the full MIMIC dataset when available\n",
    "2. Exploring combinations of techniques (e.g., SMOTE + class weights)\n",
    "3. Trying different base classifiers (e.g., random forest, XGBoost)\n",
    "4. Implementing more advanced techniques like ADASYN, SMOTETomek, or SMOTEENN\n",
    "5. Exploring threshold optimization for each technique"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
