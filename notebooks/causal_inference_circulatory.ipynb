{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Causal Inference: Effect of Prior Circulatory Diagnosis on Readmission\n",
    "\n",
    "**Objective:** Investigate the causal effect of having a prior diagnosis related to the 'Circulatory System' (based on ICD-9 chapters) on the risk of 30-day hospital readmission, controlling for patient age.\n",
    "\n",
    "**Method:** Propensity Score Matching (PSM) using Nearest Neighbors.\n",
    "\n",
    "**Key Steps:**\n",
    "1. Load Data\n",
    "2. Define Treatment, Outcome, and Covariates\n",
    "3. Estimate Propensity Scores\n",
    "4. Perform Matching\n",
    "5. Check Covariate Balance\n",
    "6. Estimate Treatment Effect (ATT)\n",
    "7. Discuss Assumptions and Limitations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data and Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Add project root for utils\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "\n",
    "from src.utils import load_config, get_data_path\n",
    "\n",
    "# Load config and data path\n",
    "config = load_config()\n",
    "data_path = get_data_path('processed', 'combined_features', config)\n",
    "\n",
    "# Load data\n",
    "try:\n",
    "    df = pd.read_csv(data_path)\n",
    "    print(f\"Data loaded successfully from {data_path}. Shape: {df.shape}\")\n",
    "    # Display first few rows and columns\n",
    "    pd.set_option('display.max_columns', 100)\n",
    "    display(df.head())\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: Data file not found at {data_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading data: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define Treatment, Outcome, and Covariates\n",
    "\n",
    "- **Treatment (T):** Binary indicator (1 if patient has a prior diagnosis in the 'Diseases of the Circulatory System' ICD-9 chapter (390-459), 0 otherwise). We need to identify the relevant diagnosis columns created during feature engineering.\n",
    "- **Outcome (Y):** `readmission_30day` (binary).\n",
    "- **Covariates (X):** `age` (continuous). We might add more later (e.g., gender, other comorbidities) but start simple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify diagnosis columns related to circulatory system (assuming they exist)\n",
    "# This depends heavily on how diagnosis features were created.\n",
    "# Example: Assuming one-hot encoded columns like 'diag_cat_circulatory_system'\n",
    "circulatory_diag_col = 'diag_cat_diseases_of_the_circulatory_system' # Placeholder - ADJUST BASED ON ACTUAL FEATURE NAME\n",
    "\n",
    "if circulatory_diag_col not in df.columns:\n",
    "    print(f\"Error: Assumed treatment column '{circulatory_diag_col}' not found.\")\n",
    "    print(\"Available columns:\", df.columns.tolist())\n",
    "    # You might need to reconstruct this feature based on raw diagnosis codes if not present\n",
    "    # Or adjust the column name based on feature engineering output.\n",
    "    treatment_defined = False\n",
    "else:\n",
    "    df['treatment'] = df[circulatory_diag_col].apply(lambda x: 1 if x > 0 else 0) # Ensure binary\n",
    "    treatment_defined = True\n",
    "    print(f\"Treatment column ('{circulatory_diag_col}') found and processed.\")\n",
    "\n",
    "# Define outcome\n",
    "outcome_col = 'readmission_30day'\n",
    "if outcome_col not in df.columns:\n",
    "    print(f\"Error: Outcome column '{outcome_col}' not found.\")\n",
    "    outcome_defined = False\n",
    "else:\n",
    "    df['outcome'] = df[outcome_col]\n",
    "    outcome_defined = True\n",
    "    print(f\"Outcome column ('{outcome_col}') found.\")\n",
    "\n",
    "# Define covariates\n",
    "covariate_cols = ['age'] # Start with age\n",
    "covariates_defined = all(c in df.columns for c in covariate_cols)\n",
    "if not covariates_defined:\n",
    "    print(f\"Error: Not all covariate columns ({covariate_cols}) found.\")\n",
    "else:\n",
    "     print(f\"Covariate columns ({covariate_cols}) found.\")\n",
    "\n",
    "# Filter data to necessary columns and drop rows with NaNs in these specific columns\n",
    "required_cols = ['treatment', 'outcome'] + covariate_cols\n",
    "analysis_df = None\n",
    "if treatment_defined and outcome_defined and covariates_defined:\n",
    "    analysis_df = df[required_cols].copy()\n",
    "    initial_rows = len(analysis_df)\n",
    "    analysis_df.dropna(inplace=True)\n",
    "    final_rows = len(analysis_df)\n",
    "    print(f\"\\nAnalysis DataFrame created. Dropped {initial_rows - final_rows} rows due to NaNs in required columns.\")\n",
    "    print(f\"Final shape for analysis: {analysis_df.shape}\")\n",
    "    display(analysis_df.head())\n",
    "    display(analysis_df.describe())\n",
    "    print(\"\\nTreatment group counts:\")\n",
    "    print(analysis_df['treatment'].value_counts())\n",
    "else:\n",
    "    print(\"\\nCannot proceed with analysis due to missing columns.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Estimate Propensity Scores\n",
    "\n",
    "We estimate the probability of receiving the treatment (having a prior circulatory diagnosis) given the covariates (age). We'll use Logistic Regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if analysis_df is not None:\n",
    "    # Define features (X) and target (T) for propensity score model\n",
    "    X = analysis_df[covariate_cols]\n",
    "    T = analysis_df['treatment']\n",
    "\n",
    "    # Add constant for statsmodels\n",
    "    X_const = sm.add_constant(X)\n",
    "\n",
    "    # Fit logistic regression model\n",
    "    # Using statsmodels for more detailed output, could use sklearn too\n",
    "    logit_model = sm.Logit(T, X_const)\n",
    "    try:\n",
    "        ps_model_results = logit_model.fit(disp=0) # disp=0 suppresses convergence messages\n",
    "        print(ps_model_results.summary())\n",
    "\n",
    "        # Predict propensity scores\n",
    "        analysis_df['propensity_score'] = ps_model_results.predict(X_const)\n",
    "\n",
    "        # Visualize propensity score distribution\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        sns.histplot(data=analysis_df, x='propensity_score', hue='treatment', kde=True, stat='density', common_norm=False)\n",
    "        plt.title('Propensity Score Distribution by Treatment Group')\n",
    "        plt.xlabel('Estimated Propensity Score')\n",
    "        plt.show()\n",
    "\n",
    "        print(\"\\nPropensity score summary statistics:\")\n",
    "        print(analysis_df.groupby('treatment')['propensity_score'].describe())\n",
    "        propensity_scores_estimated = True\n",
    "    except Exception as e:\n",
    "        print(f\"Error fitting propensity score model: {e}\")\n",
    "        propensity_scores_estimated = False\n",
    "else:\n",
    "    print(\"Analysis DataFrame not available. Skipping propensity score estimation.\")\n",
    "    propensity_scores_estimated = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Common Support Check:** Examine the histograms above. We need overlap in the propensity scores between the treated and control groups. If there are regions where only treated or only control units exist, matching may not be reliable for those units (lack of common support)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Perform Matching\n",
    "\n",
    "We'll use 1-to-1 nearest neighbor matching based on the propensity score *without* replacement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if analysis_df is not None and propensity_scores_estimated:\n",
    "    treated = analysis_df[analysis_df['treatment'] == 1]\n",
    "    control = analysis_df[analysis_df['treatment'] == 0]\n",
    "\n",
    "    if treated.empty or control.empty:\n",
    "        print(\"Error: One or both treatment/control groups are empty. Cannot perform matching.\")\n",
    "        matching_performed = False\n",
    "    else:\n",
    "        # Use NearestNeighbors from sklearn\n",
    "        nn = NearestNeighbors(n_neighbors=1, algorithm='ball_tree')\n",
    "        nn.fit(control[['propensity_score']])\n",
    "\n",
    "        # Find the nearest control neighbor for each treated unit\n",
    "        distances, indices = nn.kneighbors(treated[['propensity_score']])\n",
    "\n",
    "        # Create matched control group\n",
    "        matched_control_indices = control.iloc[indices.flatten()].index\n",
    "        matched_control = control.loc[matched_control_indices]\n",
    "\n",
    "        # Combine treated and matched controls into a final matched dataset\n",
    "        matched_df = pd.concat([treated, matched_control], ignore_index=True)\n",
    "\n",
    "        print(f\"Matching complete. Matched dataset shape: {matched_df.shape}\")\n",
    "        print(\"\\nMatched dataset treatment counts:\")\n",
    "        print(matched_df['treatment'].value_counts())\n",
    "        matching_performed = True\n",
    "else:\n",
    "    print(\"Propensity scores not estimated or data missing. Skipping matching.\")\n",
    "    matching_performed = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Check Covariate Balance\n",
    "\n",
    "After matching, the distribution of covariates (age) should be similar between the treated and matched control groups. We check this using the Standardized Mean Difference (SMD)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_smd(group1, group2, var):\n",
    "    \"\"\"Calculates the standardized mean difference for a variable.\"\"\"\n",
    "    mean1, mean2 = group1[var].mean(), group2[var].mean()\n",
    "    std1, std2 = group1[var].std(), group2[var].std()\n",
    "    # Pooled standard deviation\n",
    "    pooled_std = np.sqrt((std1**2 + std2**2) / 2)\n",
    "    if pooled_std == 0:\n",
    "        return np.nan # Avoid division by zero\n",
    "    return (mean1 - mean2) / pooled_std\n",
    "\n",
    "if matching_performed:\n",
    "    balance_results = {}\n",
    "    \n",
    "    # Balance before matching\n",
    "    print(\"--- Balance Before Matching ---\")\n",
    "    treated_before = analysis_df[analysis_df['treatment'] == 1]\n",
    "    control_before = analysis_df[analysis_df['treatment'] == 0]\n",
    "    for cov in covariate_cols:\n",
    "        smd_before = calculate_smd(treated_before, control_before, cov)\n",
    "        balance_results[cov] = {'SMD Before': smd_before}\n",
    "        print(f\"{cov}: SMD = {smd_before:.4f}\")\n",
    "\n",
    "    # Balance after matching\n",
    "    print(\"\\n--- Balance After Matching ---\")\n",
    "    treated_after = matched_df[matched_df['treatment'] == 1]\n",
    "    control_after = matched_df[matched_df['treatment'] == 0]\n",
    "    for cov in covariate_cols:\n",
    "        smd_after = calculate_smd(treated_after, control_after, cov)\n",
    "        balance_results[cov]['SMD After'] = smd_after\n",
    "        print(f\"{cov}: SMD = {smd_after:.4f}\")\n",
    "\n",
    "    # Generally, SMD < 0.1 indicates good balance\n",
    "    balance_df = pd.DataFrame(balance_results).T\n",
    "    display(balance_df)\n",
    "    balance_checked = True\n",
    "else:\n",
    "    print(\"Matching not performed. Skipping balance check.\")\n",
    "    balance_checked = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Estimate Treatment Effect (ATT)\n",
    "\n",
    "We estimate the Average Treatment Effect on the Treated (ATT) by comparing the outcome (`readmission_30day`) between the treated group and the matched control group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if matching_performed and balance_checked:\n",
    "    # Simple difference in means for the outcome in the matched sample\n",
    "    mean_outcome_treated = matched_df[matched_df['treatment'] == 1]['outcome'].mean()\n",
    "    mean_outcome_control = matched_df[matched_df['treatment'] == 0]['outcome'].mean()\n",
    "\n",
    "    att_estimate = mean_outcome_treated - mean_outcome_control\n",
    "\n",
    "    print(f\"Mean outcome (readmission) for Treated group (matched): {mean_outcome_treated:.4f}\")\n",
    "    print(f\"Mean outcome (readmission) for Control group (matched): {mean_outcome_control:.4f}\")\n",
    "    print(f\"\\nEstimated ATT (Difference in Means): {att_estimate:.4f}\")\n",
    "\n",
    "    # Optional: Use regression on the matched dataset for potentially more robust estimation\n",
    "    # Y ~ T + X (using matched_df)\n",
    "    X_matched = matched_df[covariate_cols]\n",
    "    T_matched = matched_df['treatment']\n",
    "    Y_matched = matched_df['outcome']\n",
    "    X_matched_const = sm.add_constant(pd.concat([T_matched, X_matched], axis=1))\n",
    "\n",
    "    try:\n",
    "        ols_model = sm.OLS(Y_matched, X_matched_const)\n",
    "        ols_results = ols_model.fit()\n",
    "        print(\"\\n--- OLS Regression on Matched Data ---\")\n",
    "        print(ols_results.summary())\n",
    "        att_regression = ols_results.params['treatment']\n",
    "        print(f\"\\nEstimated ATT (from OLS coefficient): {att_regression:.4f}\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\nError fitting OLS model on matched data: {e}\")\n",
    "\n",
    "else:\n",
    "    print(\"Matching or balance check failed. Skipping ATT estimation.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Discussion: Assumptions and Limitations\n",
    "\n",
    "**Assumptions:**\n",
    "1.  **Stable Unit Treatment Value Assumption (SUTVA):** An individual's outcome is only affected by their own treatment status, not the treatment status of others, and there's only one version of the treatment.\n",
    "2.  **Ignorability / Unconfoundedness:** Conditional on the observed covariates (age), the treatment assignment is independent of the potential outcomes. This is a strong assumption – it means we've measured and controlled for *all* factors that influence both the likelihood of having a circulatory diagnosis *and* the likelihood of readmission. This is likely **violated** here as 'age' is insufficient. We would need to include many more clinical variables (other comorbidities, severity scores, lab values, etc.) to make this more plausible.\n",
    "3.  **Positivity / Common Support:** For every combination of covariates, there is a non-zero probability of being both treated and untreated. We checked this visually with the propensity score overlap.\n",
    "\n",
    "**Limitations:**\n",
    "- **Observational Data:** We cannot definitively prove causation, only estimate association while controlling for observed confounders.\n",
    "- **Unmeasured Confounding:** The Ignorability assumption is hard to satisfy. Factors not included in our covariates (e.g., socioeconomic status, specific procedures, medication adherence, unmeasured disease severity) could bias the results.\n",
    "- **Model Dependence:** The results depend on the correctness of the propensity score model (logistic regression).\n",
    "- **Matching Quality:** Nearest neighbor matching can sometimes result in poor matches if good controls aren't available (check distances if needed). It also discards unmatched units, potentially changing the population the results generalize to.\n",
    "- **Simplified Analysis:** This is a basic example using only age. A real-world analysis would require careful selection and inclusion of many more relevant covariates and potentially more advanced methods (e.g., Doubly Robust Estimation)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
